{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook contains code snippets we wrote for preprocessing our corpora before training our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing words without spaces (Urdu only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(filename):\n",
    "    \"\"\"Returns a list of words from filename\"\"\"\n",
    "    words = []\n",
    "    \n",
    "    with open(filename, encoding=\"utf-8\", errors='ignore') as text_file:\n",
    "        for line in text_file:\n",
    "            words.append(line)\n",
    "            \n",
    "    return words\n",
    "\n",
    "def get_words_without_spaces():\n",
    "    \"\"\"Returns the list of words without spaces\"\"\"   \n",
    "    file_1 = get_words(\"urdu_words_without_spaces_1.txt\")\n",
    "    file_2 = get_words(\"urdu_words_without_spaces_2.txt\")\n",
    "    file_3 = get_words(\"urdu_words_without_spaces_3.txt\")    \n",
    "    \n",
    "    words_without_spaces = file_1 + file_2 + file_3            \n",
    "    words_without_spaces = [line.strip() for line in words_without_spaces]\n",
    "            \n",
    "    return words_without_spaces\n",
    "\n",
    "def get_words_with_spaces():\n",
    "    \"\"\"Returns the list of words with spaces\"\"\"    \n",
    "    file_1 = get_words(\"urdu_words_with_spaces_1.txt\")\n",
    "    file_2 = get_words(\"urdu_words_with_spaces_2.txt\")\n",
    "    file_3 = get_words(\"urdu_words_with_spaces_3.txt\")\n",
    "    \n",
    "    words_with_spaces = file_1 + file_2 + file_3            \n",
    "    words_with_spaces = [line.strip() for line in words_with_spaces]\n",
    "            \n",
    "    return words_with_spaces\n",
    "\n",
    "def fix_lines(input_file, output_file, words_without_spaces, words_with_spaces):\n",
    "    \"\"\" Writes each sentence from the input file to the output file, fixing space-less words\"\"\"\n",
    "    with open(input_file, encoding=\"utf-8\", errors='ignore') as i_f,\\\n",
    "    open(output_file, \"w\", encoding=\"utf-8\", errors='ignore') as o_f:\n",
    "        i = 0\n",
    "        words_modified = 0\n",
    "        lines_modified = 0\n",
    "        \n",
    "        for sentence in i_f:\n",
    "            index = 0\n",
    "            flag = True\n",
    "            for words in words_without_spaces:\n",
    "                if words in sentence:\n",
    "                    sentence = sentence.replace(words, words_with_spaces[index])  \n",
    "                    words_modified += 1\n",
    "                    flag = False                  \n",
    "\n",
    "                index += 1\n",
    "            o_f.write(sentence)\n",
    "\n",
    "            if flag == False:\n",
    "                lines_modified += 1\n",
    "\n",
    "            if i % 100000 == 0:\n",
    "                print(\"Processed {}00K lines...\".format(int(i / 100000)))\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_without_spaces = get_words_without_spaces()\n",
    "words_with_spaces = get_words_with_spaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_lines(\"urdu.txt\", \"urdu_fixed.txt\", words_without_spaces, words_with_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'roman.txt'\n",
    "output_file = 'roman_preprocessed.txt'\n",
    "\n",
    "temp_file_a = 'temp_a.txt'\n",
    "temp_file_b = 'temp_b.txt'\n",
    "temp_file_c = 'temp_c.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "with open(input_file, encoding='utf-8', errors='ignore') as i_f,\\\n",
    "    open(temp_file_a, mode='w', encoding='utf-8', errors='ignore') as o_f:\n",
    "    for sentence in i_f:\n",
    "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "        o_f.write(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(temp_file_a, encoding='utf-8', errors='ignore') as i_f,\\\n",
    "    open(temp_file_b, 'w', encoding='utf-8', errors='ignore') as o_f:\n",
    "    for sentence in i_f:\n",
    "        o_f.write(\"\".join([character for character in sentence if not character.isdigit()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing multiple whitespace characters with single whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'roman' in input_file:\n",
    "    with open(temp_file_b, encoding='utf-8', errors='ignore') as i_f,\\\n",
    "    open(temp_file_c, 'w', encoding='utf-8', errors='ignore') as o_f:\n",
    "        for sentence in i_f:\n",
    "            words = sentence.split()\n",
    "            l = len(words)\n",
    "\n",
    "            for i in range(l):\n",
    "                if i == (l - 1):\n",
    "                    o_f.write(words[i] + '\\n')\n",
    "                else:\n",
    "                    o_f.write(words[i] + ' ')\n",
    "else:\n",
    "    with open(temp_file_b, encoding='utf-8', errors='ignore') as i_f,\\\n",
    "    open(output_file, 'w', encoding='utf-8', errors='ignore') as o_f:\n",
    "        for sentence in i_f:\n",
    "            words = sentence.split()\n",
    "            l = len(words)\n",
    "\n",
    "            for i in range(l):\n",
    "                if i == (l - 1):\n",
    "                    o_f.write(words[i] + '\\n')\n",
    "                else:\n",
    "                    o_f.write(words[i] + ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting all characters to lowercase (Roman Urdu only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(temp_file_c) as i_f, open(output_file, 'w') as o_f:\n",
    "    for sentence in i_f:\n",
    "        sentence = sentence.lower()\n",
    "        o_f.write(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
