{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5_rGQISuqDoY"
   },
   "source": [
    "# Google Drive code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Mz2xuj5gaqy"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7naMCy9gigpd"
   },
   "outputs": [],
   "source": [
    "# These variables define the path and filenames\n",
    "\n",
    "root = \"/content/drive/My Drive\" # Do not edit this one!\n",
    "path = \"/Shared/FYP/Data\"\n",
    "filename = \"/urdu_fixed.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VdY6l3erqUq7"
   },
   "source": [
    "# Loading and processing the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5r0G7DuMjQKz"
   },
   "outputs": [],
   "source": [
    "def get_lines(root, path, filename):\n",
    "    \"\"\" Returns processed lines from the file at the given path\"\"\"\n",
    "    lines = []\n",
    "\n",
    "    with open(root + path + filename, \"rb\") as text_file:\n",
    "        lines.extend(text_file.readlines())\n",
    "        text_file.close()\n",
    "        \n",
    "    lines = [x.decode(\"utf-8\", \"ignore\") for x in lines]\n",
    "    lines = [i.strip() for i in lines]\n",
    "    lines = [i.split() for i in lines]\n",
    "\n",
    "    return lines\n",
    "\n",
    "lines = get_lines(root, path, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlmrDt46qZ48"
   },
   "source": [
    "# Training a word2vec model\n",
    "\n",
    "## Usage\n",
    "Word2Vec(sentences=None, corpus_file=None, size=100, alpha=0.025, window=5, min_count=5, max_vocab_size=None,\n",
    "         sample=0.001, seed=1, workers=3, min_alpha=0.0001, sg=0, hs=0, negative=5, ns_exponent=0.75, cbow_mean=1,\n",
    "         hashfxn=<built-in function hash>, iter=5, null_word=0, trim_rule=None, sorted_vocab=1, batch_words=10000,\n",
    "         compute_loss=False, callbacks=(), max_final_vocab=None)\n",
    "\n",
    "## Important parameters\n",
    "1. **min_count** = int - Ignores all words with total absolute frequency lower than this - (2, 100)\n",
    "2. **window** = int - The maximum distance between the current and predicted word within a sentence. E.g. window words on the left and window words on the left of our target - (2, 10)\n",
    "3. **size** = int - Dimensionality of the feature vectors. - (50, 300)\n",
    "4. **sample** = float - The threshold for configuring which higher-frequency words are randomly downsampled. Highly influencial. - (0, 1e-5)\n",
    "5. **alpha** = float - The initial learning rate - (0.01, 0.05)\n",
    "6. **min_alpha** = float - Learning rate will linearly drop to min_alpha as training progresses. To set it: alpha - (min_alpha * epochs) ~ 0.00\n",
    "7.  **negative** = int - If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drown. If set to 0, no negative sampling is used. - (5, 20)\n",
    "8. **workers** = int - Use these many worker threads to train the model (= faster training with multicore machines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XufqWU_rk000"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(lines, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9LGww4IQOUZ"
   },
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fHFPCWIoK_y"
   },
   "outputs": [],
   "source": [
    "model_name = 'word2vec_urdu_sg'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WmH9ey5KqfIR"
   },
   "source": [
    "# Downloading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v2jOOuyZotAW"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "try:\n",
    "    files.download(model_name)\n",
    "except ConnectionResetError:\n",
    "    print(\"Encountered ConnectionResetError! The file download is incomplete\")\n",
    "except TypeError:\n",
    "    print(\"Encountered TypeError!\")\n",
    "except NameError:\n",
    "    print(\"Encountered NameError!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "word2vec_gensim_train.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
