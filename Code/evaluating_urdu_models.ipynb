{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "evaluating_urdu_models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5b-rSJsWOi7M"
      },
      "source": [
        "# Evaluating Urdu Models\n",
        "\n",
        "This notebook was written to perform both qualitative and quantitative analysis of the various word embedding models we trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6oUNxf4Xpo8",
        "colab_type": "text"
      },
      "source": [
        "#### Hiding warnings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cBjxZnJQdgnM",
        "colab": {}
      },
      "source": [
        "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
        "matplotlib_axes_logger.setLevel('ERROR')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCZ7DbQ0XtEO",
        "colab_type": "text"
      },
      "source": [
        "#### Colab-specific statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuUBPArmC4l_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    !pip install arabic_reshaper python-bidi\n",
        "    print()\n",
        "\n",
        "    drive.mount('/content/drive/')\n",
        "\n",
        "    base = '/content/drive/My Drive/Shared/FYP/'\n",
        "except:\n",
        "    base = 'C:/Users/Ali/Google Drive/Shared/FYP/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UjujGr7_Prw3"
      },
      "source": [
        "## Loading Models\n",
        "\n",
        "#### Defining paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkx2dZcOCMNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "word2vec_cbow_path = os.path.join(base, 'Models/Word2Vec/Ours/word2vec_urdu_cbow_500')\n",
        "word2vec_sg_path = os.path.join(base, 'Models/Word2Vec/Ours/word2vec_urdu_sg_500')\n",
        "\n",
        "glove_path =  os.path.join(base, 'Models/GloVe/glove_urdu_500.txt')\n",
        "\n",
        "fasttext_cbow_path =  os.path.join(base, 'Models/fastText/urdu_cbow/fasttext_urdu_cbow_500')\n",
        "fasttext_sg_path =  os.path.join(base, 'Models/fastText/urdu_sg/fasttext_urdu_sg_500')\n",
        "\n",
        "wordsim_path = 'Evaluation/wordsim353_urdu.tsv'\n",
        "simlex_path = 'Evaluation/simlex999_urdu.tsv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kq4H_xhCMNt",
        "colab_type": "text"
      },
      "source": [
        "#### Loading Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ISih_gLEQFfr",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "word2vec_cbow = Word2Vec.load(word2vec_cbow_path)\n",
        "word2vec_cbow = word2vec_cbow.wv\n",
        "\n",
        "word2vec_sg = Word2Vec.load(word2vec_sg_path)\n",
        "word2vec_sg = word2vec_sg.wv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JA75Mtj8P9uf"
      },
      "source": [
        "#### Loading GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xzCYQ9o9QeOi",
        "colab": {}
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "glove = KeyedVectors.load_word2vec_format(glove_path, binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qskxSepJQCep"
      },
      "source": [
        "#### Loading fastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYdb6om0Qe6L",
        "colab": {}
      },
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "fasttext_cbow = FastText.load(fasttext_cbow_path)\n",
        "fasttext_cbow = fasttext_cbow.wv\n",
        "\n",
        "fasttext_sg = FastText.load(fasttext_sg_path)\n",
        "fasttext_sg = fasttext_sg.wv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ACKsi0hhR9nn"
      },
      "source": [
        "## Displaying PCA Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3O0Ojo8EgQJ",
        "colab_type": "text"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bdFLiR3gxsys",
        "colab": {}
      },
      "source": [
        "#https://web.stanford.edu/class/cs224n/materials/Gensim%20word%20vector%20visualization.html\n",
        "#https://raw.githubusercontent.com/devmount/GermanWordEmbeddings/master/visualize.py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from arabic_reshaper import reshape\n",
        "from bidi.algorithm import get_display\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def display_pca_scatterplot(model, words, title='', filename=''):\n",
        "    \"\"\" Displays a scatter plot for the word-word pairs\"\"\"\n",
        "    word_vectors = [model[w] for w in words]\n",
        "    pca = PCA(n_components=2)\n",
        "    reduced_vectors = pca.fit_transform(word_vectors)\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    fig.suptitle(title, fontsize=20)\n",
        "    plt.scatter(reduced_vectors[:, 0], reduced_vectors[:, 1], c='g')\n",
        "\n",
        "    for word, (x, y) in zip(words, reduced_vectors):\n",
        "        reshaped_word = reshape(word)\n",
        "        displayed_word = get_display(reshaped_word)\n",
        "        plt.text(x + 0.05, y + 0.05, s=displayed_word)\n",
        "\n",
        "    # Plotting arrows\n",
        "    for i in range(0, len(words) - 1, 2):\n",
        "        a = reduced_vectors[i][0] + 0.04\n",
        "        b = reduced_vectors[i][1]\n",
        "        c = reduced_vectors[i + 1][0] - 0.04\n",
        "        d = reduced_vectors[i + 1][1]\n",
        "        plt.arrow(\n",
        "            a, b, c - a, d - b,\n",
        "            shape='full',\n",
        "            lw=0.1,\n",
        "            edgecolor='#bbbbbb',\n",
        "            facecolor='#bbbbbb',\n",
        "            length_includes_head=True,\n",
        "            head_width=0.08,\n",
        "            width=0.01\n",
        "        )\n",
        "\n",
        "    if filename:\n",
        "        plt.savefig(filename, format='png', dpi=300, bbox_inches='tight')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QkKLoZuBa4fU"
      },
      "source": [
        "### Word Lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m9BS9UHvZg0c",
        "colab": {}
      },
      "source": [
        "countries = ['انگلینڈ', 'لنڈن', 'افغانستان', 'کابل', 'جاپان', 'ٹوکیو', 'عراق', 'بغداد']\n",
        "synonyms = ['ہنس', 'مسکرا', 'دلکش', 'خوبصورت', 'خدا', 'پروردگار']\n",
        "antonyms = ['ہنسنا', 'رونا', 'بیٹھنا' ,'چلنا', 'شام', 'صبح']\n",
        "sing_plu = ['بیٹا', 'بیٹے', 'بیٹی', 'بیٹیاں']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QOBh_dGRYxe3"
      },
      "source": [
        "### Word2Vec Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wU8Z46GWZLSh"
      },
      "source": [
        "#### Countries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DT1za39JZKqL",
        "colab": {}
      },
      "source": [
        "display_pca_scatterplot(word2vec_cbow, countries, 'Word2Vec Urdu CBOW 500 - Countries', 'word2vec_urdu_cbow_500_countries.png')\n",
        "display_pca_scatterplot(word2vec_sg, countries, 'Word2Vec Urdu SG 500 - Countries', 'word2vec_urdu_sg_500_countries.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a6rAnbQhaAse"
      },
      "source": [
        "#### Synonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KCFsTiTFaAsf",
        "colab": {}
      },
      "source": [
        "display_pca_scatterplot(word2vec_cbow, synonyms, 'Word2Vec Urdu CBOW 500 - Synonyms', 'word2vec_urdu_cbow_500_synonyms.png')\n",
        "display_pca_scatterplot(word2vec_sg, synonyms, 'Word2Vec Urdu SG 500 - Synonyms', 'word2vec_urdu_sg_500_synonyms.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AphhwLI1Y8ZO"
      },
      "source": [
        "### GloVe Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vx-Jzk_zZ_CR"
      },
      "source": [
        "#### Countries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2OehkFi6Z_CV",
        "colab": {}
      },
      "source": [
        "display_pca_scatterplot(glove, countries, 'GloVe Urdu 500 - Countries', 'glove_urdu_sg_500_countries.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KhaXE-3TaIqm"
      },
      "source": [
        "#### Synonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dXpz8x0TaIqn",
        "colab": {}
      },
      "source": [
        "display_pca_scatterplot(glove, synonyms, 'GloVe Urdu 500 - Synonyms', 'glove_urdu_sg_500_synonyms.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-c7vsqPY8io"
      },
      "source": [
        "### fastText Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "emaGO2rSZ_pY"
      },
      "source": [
        "#### Countries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fD6e2uUiZ_pZ",
        "colab": {}
      },
      "source": [
        "display_pca_scatterplot(fasttext_cbow, countries, 'FastText Urdu CBOW 500 - Countries', 'fasttext_urdu_cbow_500_countries.png')\n",
        "display_pca_scatterplot(fasttext_sg, countries, 'FastText Urdu SG 500 - Countries', 'fasttext_urdu_sg_500_countries.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZEpIGSvsaJa9"
      },
      "source": [
        "#### Synonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dq9pwkQkaJa-",
        "colab": {}
      },
      "source": [
        "display_pca_scatterplot(fasttext_cbow, synonyms, 'FastText Urdu CBOW 500 - Synonyms', 'fasttext_urdu_cbow_500_synonyms.png')\n",
        "display_pca_scatterplot(fasttext_sg, synonyms, 'FastText Urdu SG 500 - Synonyms', 'fasttext_urdu_sg_500_synonyms.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3T-UadXwSXgD"
      },
      "source": [
        "## Displaying TSNE Scatter Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRvcAtvwEjdy",
        "colab_type": "text"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GZcNOgAFdgnU",
        "colab": {}
      },
      "source": [
        "#https://towardsdatascience.com/google-news-and-leo-tolstoy-visualizing-word2vec-word-embeddings-with-t-sne-11558d8bd4d\n",
        "\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def build_clusters(model, words, perp):\n",
        "    \"\"\" Returns embeddings and clusters of similar words obtained from the model\"\"\"\n",
        "    embedding_clusters = []\n",
        "    word_clusters = []\n",
        "\n",
        "    for word in words:\n",
        "        embeddings = []\n",
        "        words = []\n",
        "\n",
        "        for similar_word, _ in model.most_similar(word, topn=10):\n",
        "            words.append(similar_word)\n",
        "            embeddings.append(model[similar_word])\n",
        "\n",
        "        embedding_clusters.append(embeddings)\n",
        "        word_clusters.append(words)\n",
        "\n",
        "    embedding_clusters = np.array(embedding_clusters)\n",
        "    n, m, k = embedding_clusters.shape\n",
        "    tsne_model_en_2d = TSNE(perplexity=perp, n_components=2, init='pca', n_iter=5000)\n",
        "    embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
        "\n",
        "    return embeddings_en_2d, word_clusters\n",
        "\n",
        "def tsne_plot_similar_words(title, labels, embedding_clusters, word_clusters, filename=''):\n",
        "    \"\"\" Displays scatter plots showing clusters of similar words\"\"\"\n",
        "    fig = plt.figure(figsize=(16, 9))\n",
        "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
        "\n",
        "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
        "        x = embeddings[:, 0]\n",
        "        y = embeddings[:, 1]\n",
        "        plt.scatter(x, y, c=color, alpha=0.7, label=label)\n",
        "\n",
        "        for i, word in enumerate(words):\n",
        "            reshaped_word = reshape(word)\n",
        "            displayed_word = get_display(reshaped_word)\n",
        "            plt.text(x[i] + 0.05, y[i] + 0.05, s=displayed_word)\n",
        "\n",
        "    plt.legend(loc=4)\n",
        "    fig.suptitle(title, fontsize=20)\n",
        "    plt.grid(True)\n",
        "\n",
        "    if filename:\n",
        "        plt.savefig(filename, format='png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "def gen_plot(model, words, title='', filename='', perp=35):\n",
        "    \"\"\" Calls functions to get embeddings, clusters and display the plots\"\"\"\n",
        "    embeddings_en_2d, word_clusters = build_clusters(model, words, perp)\n",
        "    tsne_plot_similar_words(title, words, embeddings_en_2d, word_clusters, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PAxINq0zh_at"
      },
      "source": [
        "The list of words used to generate clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YHdwzoG_h9z5",
        "colab": {}
      },
      "source": [
        "words = ['مذہب', 'کھانا', 'موسم', 'محبت', 'پاکستان', 'اللہ', 'مالک', 'حکومت', 'شہر', 'محمد', 'کرکٹ', 'مسلمان', 'امریکہ', 'باپ', 'صبح']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Gv4VwyGaxQV"
      },
      "source": [
        "#### Word2Vec Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ztrrxWzazEr",
        "colab": {}
      },
      "source": [
        "gen_plot(word2vec_cbow, words, 'Word2Vec CBOW 500 Urdu - Clusters', 'word2vec_urdu_cbow_500_clusters.png', 39)\n",
        "gen_plot(word2vec_sg, words, 'Word2Vec SG 500 Urdu - Clusters', 'word2vec_urdu_sg_500_clusters.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i4WrCpZ6axQX"
      },
      "source": [
        "#### GloVe Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j5hkbBBzazp3",
        "colab": {}
      },
      "source": [
        "gen_plot(glove, words, 'GloVe 500 Urdu - Clusters', 'glove_urdu_500_clusters.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DUP52OjuaxQY"
      },
      "source": [
        "#### fastText Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tqkvkKLra0Tt",
        "colab": {}
      },
      "source": [
        "gen_plot(fasttext_cbow, words, 'FastText CBOW 500 Urdu - Clusters', 'fasttext_urdu_cbow_500_clusters.png')\n",
        "gen_plot(fasttext_sg, words, 'FastText SG 500 Urdu - Clusters', 'fasttext_urdu_sg_500_clusters.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7X5_2bIlm1rF"
      },
      "source": [
        "## Performing Quantitative Analysis using Spearman's Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP1Y4uV8EpHS",
        "colab_type": "text"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc9sF9fHomf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_spearman_scores(evaluation_dataset):\n",
        "    \"\"\" Returns a dictionary of Spearman's Correlation Coefficients for the given dataset\"\"\"\n",
        "    scores_dict = {}\n",
        "\n",
        "    _, spearman_coefficient_w2v_cbow, __ = word2vec_cbow.evaluate_word_pairs(evaluation_dataset)\n",
        "    _, spearman_coefficient_w2v_sg, __ = word2vec_sg.evaluate_word_pairs(evaluation_dataset)\n",
        "\n",
        "    _, spearman_coefficient_glove, __ = glove.evaluate_word_pairs(evaluation_dataset)\n",
        "\n",
        "    _, spearman_coefficient_ft_cbow, __ = fasttext_cbow.evaluate_word_pairs(evaluation_dataset)\n",
        "    _, spearman_coefficient_ft_sg, __ = fasttext_sg.evaluate_word_pairs(evaluation_dataset)\n",
        "\n",
        "    scores_dict['Word2Vec CBOW'] = spearman_coefficient_w2v_cbow[0]\n",
        "    scores_dict['Word2Vec SG'] = spearman_coefficient_w2v_sg[0]\n",
        "    scores_dict['GloVe'] = spearman_coefficient_glove[0]\n",
        "    scores_dict['fastText CBOW'] = spearman_coefficient_ft_cbow[0]\n",
        "    scores_dict['fastText SG'] = spearman_coefficient_ft_sg[0]\n",
        "\n",
        "    return scores_dict\n",
        "\n",
        "def display_scores(scores_dict):\n",
        "    \"\"\" Displays the scores from the dictionary\"\"\"\n",
        "    for score in scores_dict:\n",
        "        print(\"{}: {:.3f}\".format(score, scores_dict[score]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUKoqbZZblUO",
        "colab_type": "text"
      },
      "source": [
        "### WordSim-353"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hn97JXSBkEIL",
        "colab": {}
      },
      "source": [
        "wordsim_file = os.path.join(base, wordsim_path)\n",
        "\n",
        "wordsim_scores = get_spearman_scores(wordsim_file)\n",
        "display_scores(wordsim_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBPHRuRSbowY",
        "colab_type": "text"
      },
      "source": [
        "### SimLex-999\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax1RZyt3brgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simlex_file = os.path.join(base, simlex_path)\n",
        "\n",
        "simlex_scores = get_spearman_scores(simlex_file)\n",
        "display_scores(simlex_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}