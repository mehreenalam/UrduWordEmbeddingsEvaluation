{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_elmo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Siy-5Ur84e2A",
        "colab_type": "text"
      },
      "source": [
        "#Training ELMo\n",
        "\n",
        "###References\n",
        "1. https://appliedmachinelearning.blog/2019/11/30/training-elmo-from-scratch-on-custom-data-set-for-generating-embeddings-tensorflow/\n",
        "2. https://github.com/allenai/bilm-tf\n",
        "\n",
        "## Setting up the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rh4SF0YsWkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#comment/uncomment MODEL_LANGUAGE according to what language you want to train ELMO for\n",
        "#MODEL_LANGUAGE = 'urdu'\n",
        "MODEL_LANGUAGE = 'roman-urdu'\n",
        "\n",
        "!git clone https://github.com/allenai/bilm-tf.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw7fvJ2pZn6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUE41bDrnsn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/bilm-tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbc9QODis3eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U73_O44rUp6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6QsZQYL1cAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm \"/content/bilm-tf/bilm/data.py\"\n",
        "!rm \"/content/bilm-tf/bin/train_elmo.py\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5oLyIop3BXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/elmo/roman_urdu/train_elmo.py\" \"/content/bilm-tf/bin/train_elmo.py\"\n",
        "#!cp \"/content/drive/My Drive/elmo/roman_urdu/data.py\" \"/content/bilm-tf/bilm/data.py\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZshF7T6q_sx",
        "colab_type": "text"
      },
      "source": [
        "## Getting the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UCroFIwUuib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_corpus(corpus):\n",
        "    lines = []\n",
        "\n",
        "    with open(corpus) as input_file:\n",
        "        lines = input_file.readlines()\n",
        "\n",
        "    return lines\n",
        "\n",
        "corpus = None\n",
        "\n",
        "%cd ..\n",
        "if MODEL_LANGUAGE == 'urdu':\n",
        "    corpus = load_corpus('/content/drive/My Drive/FYP/Corpora/Training/urdu_filtered.txt')\n",
        "else:\n",
        "    corpus = load_corpus('/content/drive/My Drive/FYP/Corpora/Training/roman_filtered.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmTYGruyrFZ_",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haBGiQqdfahc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def split_corpus(corpus, lines_per_file, save_dir):\n",
        "    # if not os.path.exists(\"/content/swb/train\"):\n",
        "    #     os.makedirs(\"/content/swb/train\")\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    for i in range(0, len(corpus), lines_per_file):\n",
        "        text = \"\\n\".join(corpus[i: i + lines_per_file])\n",
        "        \n",
        "        with open(save_dir + str(i) + \".txt\", \"w\", encoding='utf-8', errors='ignore') as fp:\n",
        "            fp.write(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6s93l2e4MJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_corpus(corpus, 1000, \"/content/swb/train/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMKtf3EcrK8l",
        "colab_type": "text"
      },
      "source": [
        "### Creating vocab file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6FjifE6kfVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tokens_dict(corpus):\n",
        "    tokens = {}\n",
        "\n",
        "    for sentence in corpus:\n",
        "        words = sentence.split()\n",
        "        for word in words:\n",
        "            if word in tokens:\n",
        "                tokens[word] += 1\n",
        "            else:\n",
        "                tokens[word] = 1\n",
        "\n",
        "    return sorted(tokens.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "def write_vocab_file(filename, tokens):\n",
        "    with open(filename, 'w', encoding='utf-8', errors='ignore') as vocab_file:\n",
        "        vocab_file.write(\"<S>\\n</S>\\n<UNK>\\n\")\n",
        "\n",
        "        for token in tokens:\n",
        "            print(\"Token: {}\".format(token))\n",
        "            print(\"Type: {}\".format(type(token)))\n",
        "            vocab_file.write(token[0] + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64GlLJBT4Sdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_dict = get_tokens_dict(corpus)\n",
        "write_vocab_file('vocab.txt', tokens_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2cM5mGHrh7Q",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgtdIeTDivX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete the file from the cloned repo\n",
        "!rm \"/content/bilm-tf/bin/train_elmo.py\"\n",
        "\n",
        "# Copy the modified file to the repo directory\n",
        "if MODEL_LANGUAGE == 'urdu':\n",
        "    !cp \"/content/drive/My Drive/FYP/elmo/urdu/train_elmo.py\" \"/content/bilm-tf/bin/train_elmo.py\"\n",
        "else:\n",
        "    !cp \"/content/drive/My Drive/FYP/elmo/roman_urdu/train_elmo.py\" \"/content/bilm-tf/bin/train_elmo.py\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj-MohKtuBjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if MODEL_LANGUAGE == 'urdu':\n",
        "    # Creating the checkpoint directory\n",
        "    if not os.path.exists(\"/content/drive/My Drive/FYP/elmo/elmo_urdu(2)/checkpoint\"):\n",
        "        os.makedirs(\"/content/drive/My Drive/FYP/elmo/elmo_urdu(2)/checkpoint\")\n",
        "\n",
        "    json_file = '{\"lstm\": {\"use_skip_connections\": true, \"projection_dim\": 500, \"cell_clip\": 3, \"proj_clip\": 3, \"dim\": 1024, \"n_layers\": 2}, \"char_cnn\": {\"activation\": \"relu\", \"filters\": [[1, 32], [2, 32], [3, 64], [4, 128], [5, 256], [6, 512], [7, 1024]], \"n_highway\": 1, \"embedding\": {\"dim\": 16}, \"n_characters\": 261, \"max_characters_per_token\": 45}}'\n",
        "\n",
        "    with open(\"/content/drive/My Drive/FYP/elmo/elmo_urdu(2)/checkpoint/options.json\", \"w\") as fp:\n",
        "        fp.write(json_file)\n",
        "else:\n",
        "    # Creating the checkpoint directory\n",
        "    if not os.path.exists(\"/content/drive/My Drive/FYP/elmo/roman_urdu(2)/checkpoint\"):\n",
        "        os.makedirs(\"/content/drive/My Drive/FYP/elmo/roman_urdu(2)/checkpoint\")\n",
        "\n",
        "    json_file = '{\"lstm\": {\"use_skip_connections\": true, \"projection_dim\": 500, \"cell_clip\": 3, \"proj_clip\": 3, \"dim\": 1024, \"n_layers\": 2}, \"char_cnn\": {\"activation\": \"relu\", \"filters\": [[1, 32], [2, 32], [3, 64], [4, 128], [5, 256], [6, 512], [7, 1024]], \"n_highway\": 1, \"embedding\": {\"dim\": 16}, \"n_characters\": 261, \"max_characters_per_token\": 15}}'\n",
        "\n",
        "    with open(\"/content/drive/My Drive/elmo/roman_urdu(2)/checkpoint/options.json\", \"w\") as fp:\n",
        "        fp.write(json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJrBB1mcmKm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if MODEL_LANGUAGE == 'urdu': \n",
        "    !python bilm-tf/bin/train_elmo.py \\\n",
        "        --train_prefix='/content/swb/train/*' \\\n",
        "        --vocab_file \"/content/drive/My Drive/FYP/elmo/elmo_urdu(2)/vocab.txt\" \\\n",
        "        --save_dir '/content/drive/My Drive/FYP/elmo/elmo_urdu(2)/checkpoint/'\n",
        "else:\n",
        "    !python bilm-tf/bin/train_elmo.py \\\n",
        "        --train_prefix='/content/swb/train/*' \\\n",
        "        --vocab_file \"/content/drive/My Drive/FYP/elmo/roman_urdu(2)/vocab.txt\" \\\n",
        "        --save_dir '/content/drive/My Drive/FYP/elmo/roman_urdu(2)/checkpoint/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OstNeJRdTOh7",
        "colab_type": "text"
      },
      "source": [
        "## Converting the TF checkpoint to hdf5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YroMpoycTYLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if MODEL_LANGUAGE == 'urdu':\n",
        "    !python bilm-tf/bin/dump_weights.py \\\n",
        "        --save_dir '/content/drive/My Drive/FYP/elmo/elmo_urdu(2)/checkpoint/' \\\n",
        "        --outfile '/content/drive/My Drive/FYP/elmo/elmo_urdu(2)/weights.hdf5'\n",
        "else:\n",
        "    !python bilm-tf/bin/dump_weights.py \\\n",
        "        --save_dir '/content/drive/My Drive/FYP/elmo/roman_urdu(2)/checkpoint/' \\\n",
        "        --outfile '/content/drive/My Drive/FYP/elmo/roman_urdu(2)/weights.hdf5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwUgMOsOIV5K",
        "colab_type": "text"
      },
      "source": [
        "# Extracting embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAiHR6acUAL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHzGvf-3IVbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We have the output of this cell on Drive, no need to execute it again!\n",
        "\n",
        "from bilm.model import dump_token_embeddings\n",
        "\n",
        "if MODEL_LANGUAGE == 'urdu':\n",
        "    #dump_token_embeddings('/content/drive/My Drive/FYP/elmo/urdu/vocab.txt',\n",
        "                          #'/content/drive/My Drive/FYP/elmo/urdu/options.json',\n",
        "                          #'/content/drive/My Drive/FYP/elmo/urdu/weights.hdf5',\n",
        "                          #'/content/drive/My Drive/FYP/elmo/urdu/embeddings.hdf5')\n",
        "    dump_token_embeddings('/content/drive/My Drive/elmo/elmo_urdu(2)/vocab.txt',\n",
        "                          '/content/drive/My Drive/elmo/elmo_urdu(2)/options.json',\n",
        "                          '/content/drive/My Drive/elmo/elmo_urdu(2)/weights.hdf5',\n",
        "                          '/content/drive/My Drive/elmo/elmo_urdu(2)/embeddings.hdf5')\n",
        "else:\n",
        "    dump_token_embeddings('/content/drive/My Drive/FYP/elmo/roman_urdu(2)/vocab.txt',\n",
        "                          '/content/drive/My Drive/FYP/elmo/roman_urdu(2)/checkpoint/options.json',\n",
        "                          '/content/drive/My Drive/FYP/elmo/roman_urdu(2)/weights.hdf5',\n",
        "                          '/content/drive/My Drive/FYP/elmo/roman_urdu(2)/embeddings.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yBxukt_JQBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "embeddings_file_path = None\n",
        "vocab_file_path = None\n",
        "\n",
        "if MODEL_LANGUAGE == 'urdu':\n",
        "\n",
        "    embeddings_file_path = 'drive/My Drive/elmo/elmo_urdu/embeddings.hdf5'\n",
        "    vocab_file_path = 'drive/My Drive/elmo/elmo_urdu/vocab.txt'\n",
        "\n",
        "else:\n",
        "    embeddings_file_path = '/content/drive/My Drive/FYP/elmo/roman_urdu/embeddings.hdf5'\n",
        "    vocab_file_path = '/content/drive/My Drive/FYP/elmo/roman_urdu/vocab.txt'\n",
        "\n",
        "embeddings_file = h5py.File(embeddings_file_path, 'r')\n",
        "arr = np.array(embeddings_file['embedding'])\n",
        "word_vector_dict = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGh2y7ENOb6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(vocab_file_path, encoding='utf-8', errors='ignore') as v_f:\n",
        "    for word, vector in zip(v_f, arr):\n",
        "        word_vector_dict[word] = vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAfNbmOXPEg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAsFv0q2OdU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('elmo_embeddings.txt', 'w', encoding='utf-8', errors='ignore') as o_f:\n",
        "    o_f.write(str(len(arr)) + \" \" + str(500))\n",
        "    \n",
        "    for key in word_vector_dict:\n",
        "        o_f.write(key)\n",
        "        for dim in word_vector_dict[key]:\n",
        "            o_f.write(str(dim) + \" \")\n",
        "        o_f.write(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm4DDkhhYNkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cat elmo_embeddings.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABKHifvqYNhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}