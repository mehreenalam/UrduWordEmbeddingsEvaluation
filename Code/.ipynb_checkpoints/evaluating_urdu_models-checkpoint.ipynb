{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5b-rSJsWOi7M"
   },
   "source": [
    "# Evaluate Urdu Models\n",
    "\n",
    "This notebook was written to perform both qualitative and quantitative analysis of the various word embedding models we trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References: \n",
    "1. https://web.stanford.edu/class/cs224n/materials/Gensim%20word%20vector%20visualization.html\n",
    "2. https://raw.githubusercontent.com/devmount/GermanWordEmbeddings/master/visualize.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6oUNxf4Xpo8"
   },
   "source": [
    "#### Hiding warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBjxZnJQdgnM"
   },
   "outputs": [],
   "source": [
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCZ7DbQ0XtEO"
   },
   "source": [
    "#### Colab-specific statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MuUBPArmC4l_"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    !pip install arabic_reshaper python-bidi\n",
    "    print()\n",
    "\n",
    "    drive.mount('/content/drive/')\n",
    "\n",
    "    base = '/content/drive/My Drive/FYP/'\n",
    "except:\n",
    "    base = 'C:/Users/Ali/Google Drive/FYP/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UjujGr7_Prw3"
   },
   "source": [
    "## Loading Models\n",
    "\n",
    "#### Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkx2dZcOCMNl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "word2vec_cbow_path = os.path.join(base, 'Models/Word2Vec/cbow-urdu/word2vec_cbow-urdu')\n",
    "word2vec_sg_path = os.path.join(base, 'Models/Word2Vec/sg-urdu/word2vec_sg-urdu')\n",
    "\n",
    "glove_path =  os.path.join(base, 'Models/GloVe/glove-urdu.txt')\n",
    "\n",
    "fasttext_cbow_path =  os.path.join(base, 'Models/fastText/cbow-urdu/fasttext_cbow-urdu')\n",
    "fasttext_sg_path =  os.path.join(base, 'Models/fastText/sg-urdu/fasttext_sg-urdu')\n",
    "\n",
    "elmo_path =  os.path.join(base, 'Models/ELMo/urdu/embeddings.txt')\n",
    "\n",
    "bert_path =  os.path.join(base, 'Models/BERT/urdu/embeddings.txt')\n",
    "\n",
    "wordsim_path = 'Evaluation/wordsim353-urdu.tsv'\n",
    "simlex_path = 'Evaluation/simlex999-urdu.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5kq4H_xhCMNt"
   },
   "source": [
    "#### Loading Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISih_gLEQFfr"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_cbow = Word2Vec.load(word2vec_cbow_path)\n",
    "word2vec_cbow = word2vec_cbow.wv\n",
    "\n",
    "word2vec_sg = Word2Vec.load(word2vec_sg_path)\n",
    "word2vec_sg = word2vec_sg.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JA75Mtj8P9uf"
   },
   "source": [
    "#### Loading GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzCYQ9o9QeOi"
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "glove = KeyedVectors.load_word2vec_format(glove_path, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qskxSepJQCep"
   },
   "source": [
    "#### Loading fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qYdb6om0Qe6L"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "fasttext_cbow = FastText.load(fasttext_cbow_path)\n",
    "fasttext_cbow = fasttext_cbow.wv\n",
    "\n",
    "fasttext_sg = FastText.load(fasttext_sg_path)\n",
    "fasttext_sg = fasttext_sg.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = KeyedVectors.load_word2vec_format(elmo_path, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = KeyedVectors.load_word2vec_format(bert_path, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ACKsi0hhR9nn"
   },
   "source": [
    "## Displaying PCA Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D3O0Ojo8EgQJ"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdFLiR3gxsys"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from arabic_reshaper import reshape\n",
    "from bidi.algorithm import get_display\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def display_word_pairs_plot(model, words, title='', filename=''):\n",
    "    \"\"\" Displays a scatter plot for the word-word pairs\"\"\"\n",
    "    word_vectors = [model[w] for w in words]\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_vectors = pca.fit_transform(word_vectors)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    plt.scatter(reduced_vectors[:, 0], reduced_vectors[:, 1], c='g')\n",
    "\n",
    "    for word, (x, y) in zip(words, reduced_vectors):\n",
    "        reshaped_word = reshape(word)\n",
    "        displayed_word = get_display(reshaped_word)\n",
    "        plt.text(x + 0.05, y + 0.05, s=displayed_word)\n",
    "\n",
    "    # Plotting arrows\n",
    "    for i in range(0, len(words) - 1, 2):\n",
    "        a = reduced_vectors[i][0] + 0.04\n",
    "        b = reduced_vectors[i][1]\n",
    "        c = reduced_vectors[i + 1][0] - 0.04\n",
    "        d = reduced_vectors[i + 1][1]\n",
    "        plt.arrow(\n",
    "            a, b, c - a, d - b,\n",
    "            shape='full',\n",
    "            lw=0.1,\n",
    "            edgecolor='#000000',\n",
    "            facecolor='#000000',\n",
    "            length_includes_head=True,\n",
    "            head_width=0.08,\n",
    "            width=0.01\n",
    "        )\n",
    "\n",
    "    if filename:\n",
    "        plt.savefig(filename, format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkKLoZuBa4fU"
   },
   "source": [
    "### Word Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9BS9UHvZg0c"
   },
   "outputs": [],
   "source": [
    "countries = ['انگلینڈ', 'لنڈن', 'افغانستان', 'کابل', 'جاپان', 'ٹوکیو', 'عراق', 'بغداد']\n",
    "synonyms = ['ہنس', 'مسکرا', 'دلکش', 'خوبصورت', 'خدا', 'پروردگار']\n",
    "antonyms = ['ہنسنا', 'رونا', 'بیٹھنا' ,'چلنا', 'شام', 'صبح']\n",
    "sing_plu = ['بیٹا', 'بیٹے', 'بیٹی', 'بیٹیاں']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOBh_dGRYxe3"
   },
   "source": [
    "### Word2Vec Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wU8Z46GWZLSh"
   },
   "source": [
    "#### Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DT1za39JZKqL"
   },
   "outputs": [],
   "source": [
    "display_word_pairs_plot(word2vec_cbow, countries, 'Word2Vec-CBOW Urdu - Countries', 'word2vec_cbow-urdu-countries.png')\n",
    "display_word_pairs_plot(word2vec_sg, countries, 'Word2Vec-SG Urdu - Countries', 'word2vec_sg-urdu-countries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6rAnbQhaAse"
   },
   "source": [
    "#### Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCFsTiTFaAsf"
   },
   "outputs": [],
   "source": [
    "display_word_pairs_plot(word2vec_cbow, synonyms, 'Word2Vec-CBOW Urdu - Synonyms', 'word2vec_cbow-urdu-synonyms.png')\n",
    "display_word_pairs_plot(word2vec_sg, synonyms, 'Word2Vec-SG Urdu - Synonyms', 'word2vec_cbow-urdu-synonyms.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AphhwLI1Y8ZO"
   },
   "source": [
    "### GloVe Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vx-Jzk_zZ_CR"
   },
   "source": [
    "#### Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OehkFi6Z_CV"
   },
   "outputs": [],
   "source": [
    "display_word_pairs_plot(glove, countries, 'GloVe Urdu - Countries', 'glove-urdu-countries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KhaXE-3TaIqm"
   },
   "source": [
    "#### Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXpz8x0TaIqn"
   },
   "outputs": [],
   "source": [
    "display_word_pairs_plot(glove, synonyms, 'GloVe Urdu - Synonyms', 'glove-urdu-synonyms.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-c7vsqPY8io"
   },
   "source": [
    "### fastText Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "emaGO2rSZ_pY"
   },
   "source": [
    "#### Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fD6e2uUiZ_pZ"
   },
   "outputs": [],
   "source": [
    "display_word_pairs_plot(fasttext_cbow, countries, 'FastText-CBOW Urdu - Countries', 'fasttext_cbow-urdu-countries.png')\n",
    "display_word_pairs_plot(fasttext_sg, countries, 'FastText-SG Urdu - Countries', 'fasttext_sg-urdu-countries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZEpIGSvsaJa9"
   },
   "source": [
    "#### Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dq9pwkQkaJa-"
   },
   "outputs": [],
   "source": [
    "display_word_pairs_plot(fasttext_cbow, synonyms, 'FastText-CBOW Urdu - Synonyms', 'fasttext_cbow-urdu-synonyms.png')\n",
    "display_word_pairs_plot(fasttext_sg, synonyms, 'FastText-SG Urdu - Synonyms', 'fasttext_sg-urdu-synonyms.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELMo Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_word_pairs_plot(elmo, countries, 'ELMo Urdu - Countries', 'elmo-urdu-countries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_word_pairs_plot(bert, countries, 'BERT Urdu - Countries', 'bert-urdu-countries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3T-UadXwSXgD"
   },
   "source": [
    "## Displaying TSNE Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRvcAtvwEjdy"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZcNOgAFdgnU"
   },
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/google-news-and-leo-tolstoy-visualizing-word2vec-word-embeddings-with-t-sne-11558d8bd4d\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def build_clusters(model, words, perp):\n",
    "    \"\"\" Returns embeddings and clusters of similar words obtained from the model\"\"\"\n",
    "    embedding_clusters = []\n",
    "    word_clusters = []\n",
    "\n",
    "    for word in words:\n",
    "        embeddings = []\n",
    "        words = []\n",
    "\n",
    "        for similar_word, _ in model.most_similar(word, topn=10):\n",
    "            words.append(similar_word)\n",
    "            embeddings.append(model[similar_word])\n",
    "\n",
    "        embedding_clusters.append(embeddings)\n",
    "        word_clusters.append(words)\n",
    "\n",
    "    embedding_clusters = np.array(embedding_clusters)\n",
    "    n, m, k = embedding_clusters.shape\n",
    "    tsne_model_en_2d = TSNE(perplexity=perp, n_components=2, init='pca', n_iter=5000)\n",
    "    embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "\n",
    "    return embeddings_en_2d, word_clusters\n",
    "\n",
    "def tsne_plot_similar_words(title, labels, embedding_clusters, word_clusters, filename=''):\n",
    "    \"\"\" Displays scatter plots showing clusters of similar words\"\"\"\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
    "\n",
    "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
    "        x = embeddings[:, 0]\n",
    "        y = embeddings[:, 1]\n",
    "        plt.scatter(x, y, c=color, alpha=0.7, label=label)\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            reshaped_word = reshape(word)\n",
    "            displayed_word = get_display(reshaped_word)\n",
    "            plt.text(x[i] + 0.05, y[i] + 0.05, s=displayed_word)\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    plt.grid(True)\n",
    "\n",
    "    if filename:\n",
    "        plt.savefig(filename, format='png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def display_cluster_plot(model, words, title='', filename='', perp=35):\n",
    "    \"\"\" Calls functions to get embeddings, clusters and display the plots\"\"\"\n",
    "    embeddings_en_2d, word_clusters = build_clusters(model, words, perp)\n",
    "    tsne_plot_similar_words(title, words, embeddings_en_2d, word_clusters, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAxINq0zh_at"
   },
   "source": [
    "The list of words used to generate clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHdwzoG_h9z5"
   },
   "outputs": [],
   "source": [
    "words = ['مذہب', 'کھانا', 'موسم', 'محبت', 'پاکستان', 'اللہ', 'مالک', 'حکومت', 'شہر', 'محمد', 'کرکٹ', 'مسلمان', 'امریکہ', 'باپ', 'صبح']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Gv4VwyGaxQV"
   },
   "source": [
    "#### Word2Vec Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ztrrxWzazEr"
   },
   "outputs": [],
   "source": [
    "display_cluster_plot(word2vec_cbow, words, 'Word2Vec-CBOW Urdu - Clusters', 'word2vec_cbow-urdu-clusters.png', 39)\n",
    "display_cluster_plot(word2vec_sg, words, 'Word2Vec-SG Urdu - Clusters', 'word2vec_sg-urdu-clusters.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4WrCpZ6axQX"
   },
   "source": [
    "#### GloVe Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5hkbBBzazp3"
   },
   "outputs": [],
   "source": [
    "display_cluster_plot(glove, words, 'GloVe Urdu - Clusters', 'glove-urdu-clusters.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DUP52OjuaxQY"
   },
   "source": [
    "#### fastText Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqkvkKLra0Tt"
   },
   "outputs": [],
   "source": [
    "display_cluster_plot(fasttext_cbow, words, 'FastText-CBOW Urdu - Clusters', 'fasttext_cbow-urdu-clusters.png')\n",
    "display_cluster_plot(fasttext_sg, words, 'FastText-SG Urdu - Clusters', 'fasttext_sg-urdu-clusters.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ELMo Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cluster_plot(elmo, words, 'ELMo Urdu - Clusters', 'elmo-urdu-clusters.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cluster_plot(bert, words, 'BERT Urdu - Clusters', 'bert-urdu-clusters.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7X5_2bIlm1rF"
   },
   "source": [
    "## Performing Quantitative Analysis using Spearman's Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yP1Y4uV8EpHS"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mc9sF9fHomf9"
   },
   "outputs": [],
   "source": [
    "def get_spearman_scores(evaluation_dataset):\n",
    "    \"\"\" Returns a dictionary of Spearman's Correlation Coefficients for the given dataset\"\"\"\n",
    "    scores_dict = {}\n",
    "\n",
    "    _, spearman_coefficient_w2v_cbow, __ = word2vec_cbow.evaluate_word_pairs(evaluation_dataset)\n",
    "    _, spearman_coefficient_w2v_sg, __ = word2vec_sg.evaluate_word_pairs(evaluation_dataset)\n",
    "    scores_dict['Word2Vec CBOW'] = spearman_coefficient_w2v_cbow[0]\n",
    "    scores_dict['Word2Vec SG'] = spearman_coefficient_w2v_sg[0]\n",
    "\n",
    "    _, spearman_coefficient_glove, __ = glove.evaluate_word_pairs(evaluation_dataset)\n",
    "    scores_dict['GloVe'] = spearman_coefficient_glove[0]\n",
    "    \n",
    "    _, spearman_coefficient_ft_cbow, __ = fasttext_cbow.evaluate_word_pairs(evaluation_dataset)\n",
    "    _, spearman_coefficient_ft_sg, __ = fasttext_sg.evaluate_word_pairs(evaluation_dataset)\n",
    "    scores_dict['fastText CBOW'] = spearman_coefficient_ft_cbow[0]\n",
    "    scores_dict['fastText SG'] = spearman_coefficient_ft_sg[0]\n",
    "    \n",
    "    _, spearman_coefficient_elmo, __ = elmo.evaluate_word_pairs(evaluation_dataset)\n",
    "    scores_dict['elmo'] = spearman_coefficient_elmo[0]\n",
    "    \n",
    "    _, spearman_coefficient_bert, __ = bert.evaluate_word_pairs(evaluation_dataset)\n",
    "    scores_dict['bert'] = spearman_coefficient_bert[0]\n",
    "\n",
    "    return scores_dict\n",
    "\n",
    "def display_scores(scores_dict):\n",
    "    \"\"\" Displays the scores from the dictionary\"\"\"\n",
    "    for score in scores_dict:\n",
    "        print(\"{}: {:.3f}\".format(score, scores_dict[score]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tUKoqbZZblUO"
   },
   "source": [
    "### WordSim-353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hn97JXSBkEIL"
   },
   "outputs": [],
   "source": [
    "wordsim_file = os.path.join(base, wordsim_path)\n",
    "\n",
    "wordsim_scores = get_spearman_scores(wordsim_file)\n",
    "display_scores(wordsim_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBPHRuRSbowY"
   },
   "source": [
    "### SimLex-999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ax1RZyt3brgT"
   },
   "outputs": [],
   "source": [
    "simlex_file = os.path.join(base, simlex_path)\n",
    "\n",
    "simlex_scores = get_spearman_scores(simlex_file)\n",
    "display_scores(simlex_scores)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "evaluating_urdu_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
